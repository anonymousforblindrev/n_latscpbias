---
title: "Analysis"
output:  
  html_document:
    number_sections: true
    toc: true  
    collapsed: false
    toc_float: true
    smooth_scroll: false
    toc_depth: 3
---

```{r setup, include=FALSE}
# packages
library(ez)
library(reshape2)
library(reshape)
library(ggplot2)
library(plyr)
library(pastecs)
library(ez)
library(data.table)
library(tidyverse) 

library(showtext)
library(readr)


font_add_google("Poppins", "Poppins")
font_add_google("Roboto Mono", "Roboto Mono")
showtext_auto()
```


```{r}
tdata <- read_csv("exp_data.csv")

tdata$dv_query <- factor(tdata$dv_query, levels = c("probability", "satisfaction_is", "satisfaction_would"), 
                               labels = c("is most \nprobable", "is most \nsatisfying", "would be \nmost satisfying"))


```


# Subject demographics

```{r}
# demographics 

min(tdata$age)
max(tdata$age)
mean(tdata$age)
sd(tdata$age)

# 1 = male, 2 = female, 3 = other
table(tdata$gender)
```

1 = male, 2 = female, 3 = non-binary, 4 = prefer not to say



```{r}
table(tdata$dv_query)
```

```{r}
# check width of the means 95% cis (none is supposed to be grater than 1)
library(rcompanion)
ci_table <- groupwiseMean(DV_rating ~ dv_query,
              data        = tdata,
              traditional = FALSE,
              percentile  = TRUE)



(ci_width <- ci_table$Percentile.upper - ci_table$Percentile.lower)
```



```{r}
tdata %>%
  group_by(dv_query) %>%
  summarise_at(vars(rating_rec), list(param=sd))
```


# Results

## Graphs

```{r}
myTheme <- theme(plot.title = element_text(face="bold", size = 22),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        axis.text.x = element_text(size = 14, angle = 0), 
        axis.text.y = element_text(size = 16, angle = 0),
        legend.text = element_text(size = 18),
        legend.title = element_text(face = "bold", size = 18),
        strip.text.x = element_text(size = 18),
        #panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.background = element_blank(), 
        axis.line.x = element_line(colour = "black"), 
        axis.line.y = element_line(colour = "black"),
        axis.text = element_text(colour ="black"), 
        axis.ticks = element_line(colour ="black"))

tdata_long <- tdata
tdata_sub <- tdata_long


library(see)
## first, turn sID into a factor
tdata_sub$subj_code <- factor(tdata_sub$subj_code)

pd <- position_dodge(width = 0.3)

tdata_sub$valueJitter <- jitter(tdata_sub$rating_rec, factor = 0.01, amount = 0.004)

theme_set(theme_light(base_size = 20, base_family = "Poppins"))

# new labes for the facets 

g <- ggplot(tdata_sub, aes(x = dv_query, y = valueJitter)) +
  guides(fill=FALSE)+
  #facet_grid( ~ dv_query)+
  #ggtitle("Subjects' causal srength ratings") +
  scale_y_continuous(limits = c(-5.3, 5.3), breaks=seq(-5, 5, 1), expand = c(0,0)) +
  #scale_x_discrete(labels=c("no \ninformation", "'You don't \nknow'")) +
  #stat_summary(fun.y = mean, geom = "bar", position = "dodge", colour = "black", alpha =0.5) +
  #geom_violinhalf(aes(y = rating_rec, group = dv_query, fill = dv_query), color = NA, 
   #               position=position_dodge(1), alpha = 0.4)+
  #geom_line(position = pd, color = "black", size = 1, alpha=0.04) +
  geom_hline(yintercept=0, linetype="dashed", color = "black")+
  geom_jitter(aes(color = dv_query), alpha = 0.5, width = 0.15, height = 0.2) +
  stat_summary(aes(y = rating_rec, group=1), fun.data = mean_cl_boot, 
               geom = "errorbar", width = 0, size = 1) +
  stat_summary(aes(y = rating_rec, group=1, color = outcome_valence), fun.y=mean, geom="line", 
               color = "black", shape = 22, size = 1, alpha = .7)+
  stat_summary(aes(y = rating_rec, group=1, fill = dv_query), fun.y=mean, geom="point", 
               color = "black", shape = 22, size = 2, group=1, alpha = 1)+
  stat_summary(aes(y = rating_rec,group=1), fun.y=median, geom="point", color = "black", shape = 3, size = 4, 
               group=1, alpha = 1, position = position_dodge(width = 0.5))+
  labs(x = "Test question", y = "Explanation rating") +
  scale_color_manual(name = "Strength",values=c("#66c2a5", "#8da0cb", "#e78ac3", "#a6d854"))+
  scale_fill_manual(name = "Strength",values=c("#66c2a5", "#8da0cb", "#e78ac3", "#a6d854"))+
  annotate("text", x = 0.5, y = 3.5, label = c("broad-scope"), angle = 90)+
  annotate("text", x = 0.5, y = -3.5, label = c("narrow-scope"), angle = 90)+
  theme(legend.position = "none")+
  myTheme+
   theme(panel.grid.major = element_line(color = "lightgrey",
                                        size = 0.5,
                                        linetype = 'dotted'))+
  stat_summary(aes(label=round(after_stat(y),2)), fun.y=mean, geom="text", size=5,
             vjust = -6)
g


ggsave("results_means_mainDV.svg",width=6,height=5)
ggsave("results_means_mainDV.pdf",width=6,height=5)
```

```{r}
library(ggridges)
g2 <- ggplot(tdata_sub, aes(x = rating_rec, y = dv_query, fill = after_stat(x))) +
  geom_density_ridges_gradient() +
  xlim(-5, 5)+
  scale_y_discrete(limits=rev)+
  scale_fill_viridis_c(name = "Explanation \nRating", option = "C", breaks=c(-5,0,5), labels=c("narrow scope", "no preference", "broad scope"))+
  labs(x = "Explanation rating", y = "Test question") +
  myTheme+
  theme_light(base_family = "Poppins", base_size = 20)+
  theme(panel.grid = element_blank(), axis.text = element_text(colour ="black"))+
  theme(legend.position="top",
        legend.title=element_blank(),legend.key.width = unit(1.95, 'cm'))

g2

#ggsave("results_dist_mainDV.svg",width=7,height=5)
#ggsave("results_dist_mainDV.pdf",width=6,height=5)
```


```{r}
library(ggridges)
g2 <- ggplot(tdata_sub, aes(x = rating_rec, y = dv_query, fill = dv_query)) +
  scale_x_continuous(breaks = seq(-5, 5, 1))+
  geom_density_ridges(alpha = 0.5)+
   #stat_summary(aes(x = rating_rec), fun.x=mean, geom="point", 
  #             color = "black", shape = 22, size = 2, group=1, alpha = 1)+
  scale_fill_manual(values=c("#66c2a5", "#8da0cb", "#e78ac3", "#a6d854"))+
  #scale_fill_viridis_c(name = "Explanation \nRating", option = "C", breaks=c(-5,0,5), labels=c("narrow scope", "no preference", "broad scope"))+
  labs(x = "Explanation rating", y = "Test question") +
  scale_y_discrete(limits=rev)+
  myTheme+
  theme_light(base_family = "Poppins", base_size = 20)+
  theme(panel.grid = element_blank(), axis.text = element_text(colour ="black"))+
  theme(legend.position="none",
        legend.title=element_blank(),legend.key.width = unit(1.95, 'cm'))+
  annotate("text", y = 0.7, x = 4, label = c("broad-scope"), angle = 0)+
  annotate("text", y = 0.7, x = -4, label = c("narrow-scope"), angle = 0)+
  theme(axis.text.y = element_text(size = 14, angle = 0))

g2

ggsave("results_dist2_mainDV.svg",width=7,height=5)
ggsave("results_dist2_mainDV.pdf",width=6,height=5)
```


Get the values of the CIs shown in the first plot:

```{r}
values <- ggplot_build(g)$data[[4]] # values are shown in the 4th panel 
values
```


get group medians: 

```{r}
# groupwiseMean(rating_rec ~ Features + Knowledge,
#               data        = tdata_long,
#               traditional = FALSE,
#               percentile  = TRUE)

groupwiseMedian(rating_rec ~ dv_query,
                data        = tdata_long,
                bca         = FALSE,
                percentile  = TRUE,
                R           = 1000)
```




## Analyses ratings

```{r, echo = FALSE, warning = FALSE, message = FALSE}
################################################################################################################
##################################### Statistical Analyses #####################################################
################################################################################################################
library(pastecs)
library(lme4)
library(nlme)
library(ez)
library(vtable)
library(rcompanion)
```


### ANOVA 

```{r}
library(afex)
a1 <- aov_car(rating_rec ~ dv_query + Error(subj_code), tdata_long, anova_table = list(es = "pes"))
a1

```

### Polynomial contrast

```{r}
contrasts(tdata_long$dv_query) <- "contr.poly"
LinearModel.1 <- lm(rating_rec ~ dv_query, data=tdata_long)
summary(LinearModel.1)
```

### Planned t-tests 

```{r}
ttestdat <- subset(tdata_long, dv_query == "is most \nprobable" | dv_query == "is most \nsatisfying")

t.test(ttestdat$rating_rec ~ ttestdat$dv_query, var.equal = F, alternative = "greater")
```


Get effect size for this difference (using the power function)

first get estimates for the standardizer 

```{r}
library(dplyr)

tdata_long %>%
  group_by(dv_query) %>%
  summarise_at(vars(rating_rec), list(name=sd))
```

```{r}
library(pwr)

# based on the difference observed in the previous study
pwr.t.test(d=(-0.15-(-0.41))/1.465,
           power=0.8,
           sig.level=0.05,
           type="two.sample",
           alternative="greater")
```



```{r}
ttestdat2 <- subset(tdata_long, dv_query == "is most \nsatisfying" | dv_query == "would be \nmost satisfying")

t.test(ttestdat2$rating_rec ~ ttestdat2$dv_query, var.equal = F, alternative = "greater")
```

```{r}
library(pwr)

# based on the difference observed in the previous study
pwr.t.test(d=(-0.41-(-0.71))/1.79,
           power=0.8,
           sig.level=0.05,
           type="two.sample",
           alternative="greater")
```




## Analysis of Subject Categories 

```{r}
counts <- tdata_long %>%
  group_by(dv_query, rating_rec) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n),
         lbl = scales::percent(pct))

counts
# shows that 0 is the mode in all conditions
```






```{r}

tdata_long$category[tdata_long$rating_rec < 0] <- "narrow"
tdata_long$category[tdata_long$rating_rec == 0] <- "unbiased"
tdata_long$category[tdata_long$rating_rec > 0] <- "broad"

counts2 <- tdata_long %>%
  group_by(dv_query, category) %>%
  summarize(n = n()) %>% 
  mutate(pct = n/sum(n),
         lbl = scales::percent(pct))

counts2

counts2$category <- factor(counts2$category, levels = c("unbiased", "narrow", "broad"), labels = c("unbiased", "narrow l.s.", "broad l.s."))

```


Get proportion CIs for different categories in each diagnosability condition:

```{r}
library(PropCIs)
library(DescTools)
library(purrr)

counts_prob <- subset(counts2, dv_query == "is most \nprobable")
counts_is_satis <- subset(counts2, dv_query == "is most \nsatisfying")
counts_would_satis <- subset(counts2, dv_query == "would be \nmost satisfying")

(MultinomCI(counts_prob$n,
           conf.level=0.95,
           method="sisonglaz") -> selection_ci_1)
  

(MultinomCI(counts_is_satis$n,
           conf.level=0.95,
           method="sisonglaz") -> selection_ci_2)
  
(MultinomCI(counts_would_satis$n,
           conf.level=0.95,
           method="sisonglaz") -> selection_ci_3)
  



ci_low <- c(selection_ci_1[,2], selection_ci_2[,2], selection_ci_3[,2])

ci_up <- c(selection_ci_1[,3], selection_ci_2[,3], selection_ci_3[,3])


```


```{r}
plotdata <- counts2

plotdata$ci_low <- ci_low
plotdata$ci_up <- ci_up
```


Plot:

```{r}

library(scales)
theme_set(theme_light(base_size = 12, base_family = "Poppins"))

# new labels for the facets 
query.labs <- c("test question: \nis most probable", "test question: \nis most satisfying", "test question: \nwould be most satisfying")
names(query.labs) <- c("is most \nprobable", "is most \nsatisfying", "would be \nmost satisfying")

g<- ggplot(plotdata, 
       aes(x = category,
           y = pct,
           fill = dv_query)) +
  facet_grid(~ dv_query, labeller = labeller(dv_query = query.labs))+
  geom_bar(stat = "identity",
           position = "dodge") +
  scale_y_continuous(limits = seq(0, 2),
                     breaks = seq(0, 1, .25),
                     expand = c(0,0),
                     label = percent) +
  #coord_cartesian(xlim =c(1, 7), ylim = c(0, 1.1))+
  #coord_cartesian(clip = "off")+
  geom_text(aes(label = lbl), 
            size = 3.5,
            position = position_dodge(width = 1),
            vjust = -3) +
  scale_fill_manual(name = "Strength",values=c("#66c2a5", "#8da0cb", "#e78ac3", "#a6d854"))+
  #scale_fill_brewer(palette = "Pastel1") +
  labs(y = "Percentage", 
       fill = "Explanatory preference",
       x = "Explanatory preference")+
  geom_pointrange(ymin = ci_low, ymax = ci_up, position = position_dodge(width = 0.89), shape = 22, size = 0.3)+
  #annotate(geom = "hline",yintercept = 0.5, y = 0.5, color = "black", size = 1, linetype='dotted')+
  #annotate("pointrange", x = plotdata$Transformation, y = plotdata$pct, 
   #        ymin = plotdata$ci_low, 
    #       ymax = plotdata$ci_up, 
     #      colour = "black", size = 0.8, shape = 22, fill = Transformation, fatten = 1)+
  #annotate("text", x = pvalues_x, y = Inf, label = pvalues, size = 4, vjust = 1.8)+
  theme(legend.position = "none", axis.title = element_text(size = 20), axis.text = element_text(size = 13, color = "black"),
        legend.text = element_text(size = 13),legend.title = element_text(size = 13),strip.text.x = element_text(size = 13))+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())

g

#ggsave("selections_between.pdf",width=6,height=5)
ggsave("categories.svg",width=11,height=5)
ggsave("categories.pdf",width=11,height=5)
```

### Proportion tests

test if the proportions of subjects showing a narrow latent scope bias differs between probability and satisfaction conditions 


"is most probable" vs. "is most satisfying": 

```{r}
prob_vs_is_sat <- prop.test(x = c(plotdata$n[2], plotdata$n[5]), n = c(240, 240), alternative = "less", correct = F)
prob_vs_is_sat 
```

"is most probable" vs. "would be most satisfying" 

```{r}
prob_vs_would_sat <- prop.test(x = c(plotdata$n[2], plotdata$n[8]), n = c(240, 240), alternative = "less", correct = F)
prob_vs_would_sat 
```



"is most satisfying" vs. "would be most satisfying"

```{r}
is_sat_vs_would_sat <- prop.test(x = c(plotdata$n[5], plotdata$n[8]), n = c(240, 240), alternative = "two.sided", correct = F)
is_sat_vs_would_sat 
```

Test if proportion of normative judgments is higher in the probability condition: 


"is most probable" vs. "is most satisfying" 

```{r}
prob_vs_is_sat <- prop.test(x = c(plotdata$n[3], plotdata$n[6]), n = c(240, 240), alternative = "greater", correct = F)
prob_vs_is_sat 
```
"is most probable" vs. "would be most satisfying" 

```{r}
prob_vs_is_sat <- prop.test(x = c(plotdata$n[3], plotdata$n[9]), n = c(240, 240), alternative = "greater", correct = F)
prob_vs_is_sat 
```
"is most satisfying" vs. "would be most satisfying" 

```{r}
is_sat_vs_would_sat <- prop.test(x = c(plotdata$n[6], plotdata$n[9]), n = c(240, 240), alternative = "greater", correct = F)
is_sat_vs_would_sat 
```






